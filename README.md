# âœˆï¸ Aviation Chatbot - RAG-Based Technical Documentation Assistant

A production-ready, AI-powered chatbot for querying aviation technical documents using Retrieval-Augmented Generation (RAG) with PostgreSQL vector database and Google Gemini LLM.

![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.31.0-red.svg)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [How It Works](#how-it-works)
- [Configuration](#configuration)
- [Deployment](#deployment)
- [Development](#development)
- [Troubleshooting](#troubleshooting)
- [Future Enhancements](#future-enhancements)
- [Contributing](#contributing)

---

## ğŸ¯ Overview

The Aviation Chatbot is an intelligent question-answering system designed for aviation professionals, students, and enthusiasts. It provides accurate, citation-backed answers from technical documentation including:

- Airport Operations manuals
- SCADA Systems documentation
- Aviation safety regulations
- Aircraft handling procedures
- And more...

**Key Innovation:** Unlike simple keyword search, this system uses semantic understanding through vector embeddings and generates contextual answers using large language models.

---

## âœ¨ Features

### Core Capabilities

- **ğŸ” Semantic Search**: Vector-based similarity search using pgvector for accurate document retrieval
- **ğŸ¤– AI-Powered Answers**: Context-aware responses generated by Google Gemini 2.5 Flash
- **ğŸ“¤ Dynamic PDF Upload**: Users can upload new documents without restarting the system
- **ğŸ“š Source Citations**: Every answer includes references to source documents and page numbers
- **ğŸ”’ Privacy Protection**: Prevents leakage of internal document details for off-topic queries
- **âš¡ Real-time Processing**: Live progress tracking for PDF ingestion
- **ğŸ’¾ Persistent Storage**: PostgreSQL database for reliable, scalable data management

### User Experience

- **ğŸ’¬ Chat Interface**: Clean, modern Streamlit UI similar to ChatGPT
- **ğŸ“Š System Monitoring**: Real-time database statistics and document management
- **ğŸ¨ Dark Theme**: Eye-friendly interface with high contrast
- **ğŸ“± Responsive Design**: Works on desktop and tablet devices
- **ğŸ—‘ï¸ Document Management**: Delete and re-upload documents as needed

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Interface (Streamlit)               â”‚
â”‚  â€¢ Chat Input/Output  â€¢ PDF Upload  â€¢ Settings  â€¢ Stats     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RAG Engine (Python)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚   Retrieval  â”‚ â—„â”€â”€â”€â”€â–º â”‚  Generation  â”‚                  â”‚
â”‚  â”‚   (Vector    â”‚         â”‚  (Gemini     â”‚                  â”‚
â”‚  â”‚   Search)    â”‚         â”‚   LLM)       â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                      â”‚
               â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL + pgvector â”‚  â”‚  Google Gemini API   â”‚
â”‚  â€¢ Document Chunks     â”‚  â”‚  â€¢ Answer Generation â”‚
â”‚  â€¢ Vector Embeddings   â”‚  â”‚  â€¢ Context Synthesis â”‚
â”‚  â€¢ Metadata            â”‚  â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–²
               â”‚
               â”‚ (Ingestion Pipeline)
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PDF Processing Pipeline                        â”‚
â”‚  PDF â†’ Extract â†’ Chunk â†’ Embed â†’ Store                     â”‚
â”‚  (pdfplumber â†’ RecursiveTextSplitter â†’ Sentence            â”‚
â”‚   Transformers â†’ PostgreSQL)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Python 3.11+**: Core programming language
- **PostgreSQL 16**: Primary database with vector extension
- **pgvector**: Vector similarity search extension
- **Streamlit**: Web application framework

### AI/ML
- **Google Gemini 2.5 Flash**: Large language model for answer generation
- **Sentence Transformers**: Text embedding model (all-MiniLM-L6-v2)
- **Hugging Face Transformers**: Model loading and tokenization

### Data Processing
- **LangChain**: Text splitting and chunking utilities
- **pdfplumber**: PDF text extraction
- **NumPy & Pandas**: Data manipulation

### Infrastructure
- **Docker**: Containerized PostgreSQL deployment
- **psycopg2**: PostgreSQL database adapter

---

## ğŸ“¥ Installation

### Prerequisites

1. **Python 3.11 or higher**
   ```bash
   python --version
   ```

2. **Docker Desktop** (for PostgreSQL)
   - Download: https://www.docker.com/products/docker-desktop

3. **Gemini API Key** (free)
   - Get it from: https://ai.google.dev/

### Step-by-Step Setup

#### 1. Clone the Repository

```bash
git clone https://github.com/nithin8688/aviation-chatbot.git
cd aviation-chatbot
```

#### 2. Create Virtual Environment

```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# Mac/Linux
source .venv/bin/activate
```

#### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

#### 4. Start PostgreSQL Container

```bash
docker run --name aviation-postgres \
  -e POSTGRES_PASSWORD=aviation123 \
  -e POSTGRES_DB=aviation_chatbot \
  -p 5432:5432 \
  -d pgvector/pgvector:pg16
```

#### 5. Configure Environment

Update `src/config.py` with your Gemini API key:

```python
GEMINI_API_KEY = "your-api-key-here"
GEMINI_MODEL = "gemini-2.5-flash"
```

Or use environment variable:
```bash
export GEMINI_API_KEY="your-api-key-here"
```

#### 6. Initialize Database

```bash
# Open setup_database.ipynb in Jupyter and run all cells
jupyter notebook notebooks/setup_database.ipynb
```

Or run the Python script:
```bash
python -c "from src.db_utils import *; setup_database()"
```

#### 7. Ingest Initial Documents

Place your PDFs in `data/raw_pdfs/` and run:

```bash
# Open unified_ingestion_to_postgres.ipynb and run all cells
jupyter notebook notebooks/unified_ingestion_to_postgres.ipynb
```

#### 8. Launch the Application

```bash
streamlit run app.py
```

The app will open at `http://localhost:8501`

---

## ğŸš€ Usage

### Asking Questions

1. **Start the App**: `streamlit run app.py`
2. **Type Your Question**: Use the chat input at the bottom
3. **View Answer**: Response appears with source citations
4. **Check Sources**: Expand "View Sources" to see document excerpts

**Example Questions:**
- "What is SCADA and how does it work?"
- "What are the responsibilities of airport apron control?"
- "Explain runway safety procedures"
- "What are the main components of airport infrastructure?"

### Uploading New Documents

1. **Click**: "ğŸ“¤ Upload New PDF" in the sidebar
2. **Select**: Choose a PDF file (max 200MB)
3. **Process**: Click "ğŸš€ Process PDF"
4. **Monitor**: Watch real-time progress bar
5. **Query**: Ask questions about the new document immediately

### Managing Documents

1. **View Stats**: Check "ğŸ“Š System Status" for database info
2. **Delete Documents**: Use "ğŸ—‘ï¸ Document Management" section
3. **Adjust Settings**: Use slider to control number of sources (3-15)

---

## ğŸ“ Project Structure

```
aviation-chatbot/
â”‚
â”œâ”€â”€ app.py                          # Main Streamlit application
â”‚
â”œâ”€â”€ src/                            # Core application code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                   # Configuration & settings
â”‚   â”œâ”€â”€ db_utils.py                 # Database operations
â”‚   â”œâ”€â”€ rag_engine.py               # RAG pipeline logic
â”‚   â””â”€â”€ ingest.py                   # PDF ingestion pipeline
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â”œâ”€â”€ 1_setup_database.ipynb        # DB initialization
â”‚   â”œâ”€â”€ 2_unified_ingestion_to_postgres.ipynb  # PDF processing
â”‚   â””â”€â”€ 3_rag_with_gemini.ipynb      # Testing queries
â”‚
â”œâ”€â”€ data/                           # Data storage
â”‚   â”œâ”€â”€ raw_pdfs/                   # Initial PDF documents
â”‚   â”œâ”€â”€ uploaded_pdfs/              # User-uploaded PDFs
â”‚   â”œâ”€â”€ chat_history.json           # Saved conversations
â”‚   â””â”€â”€ query_history.json          # Query logs
â”‚
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ .gitignore                      # Git ignore rules

```

---

## âš™ï¸ How It Works

### 1. PDF Ingestion Pipeline

```python
PDF Document
    â†“
[Extract Text] (pdfplumber)
    â†“
[Split into Chunks] (RecursiveCharacterTextSplitter)
    â”œâ”€ Chunk Size: 800 characters
    â””â”€ Overlap: 200 characters
    â†“
[Generate Embeddings] (all-MiniLM-L6-v2)
    â”œâ”€ Model: Sentence Transformers
    â””â”€ Dimension: 384
    â†“
[Store in PostgreSQL] (pgvector)
    â”œâ”€ Content: Text chunk
    â”œâ”€ Embedding: Vector[384]
    â”œâ”€ Metadata: Document name, page number
    â””â”€ Index: IVFFlat for fast search
```

### 2. Query Processing Pipeline

```python
User Question
    â†“
[Generate Query Embedding] (all-MiniLM-L6-v2)
    â†“
[Vector Similarity Search] (PostgreSQL + pgvector)
    â”œâ”€ Find top K most similar chunks (K=8 default)
    â””â”€ Cosine similarity scoring
    â†“
[Build Context] (RAG Engine)
    â”œâ”€ Combine retrieved chunks
    â””â”€ Add source metadata
    â†“
[Generate Answer] (Gemini 2.5 Flash)
    â”œâ”€ System prompt with instructions
    â”œâ”€ Context from retrieved docs
    â”œâ”€ User query
    â””â”€ Privacy protection for off-topic queries
    â†“
[Format Response]
    â”œâ”€ Answer text
    â”œâ”€ Source citations
    â””â”€ Relevance scores
    â†“
Display to User
```

### 3. Key Algorithms

**Chunking Strategy:**
- **Method**: Recursive Character Text Splitter
- **Size**: 800 characters (optimized for technical docs)
- **Overlap**: 200 characters (maintains context continuity)
- **Separators**: `["\n\n", "\n", ". ", " ", ""]`

**Embedding Model:**
- **Model**: all-MiniLM-L6-v2
- **Dimension**: 384
- **Speed**: ~32 sentences/second on CPU
- **Quality**: Good balance of speed and accuracy

**Vector Search:**
- **Index**: IVFFlat (Inverted File with Flat compression)
- **Distance**: Cosine similarity (1 - cosine distance)
- **Lists**: 100 (for index optimization)

**Answer Generation:**
- **Model**: Google Gemini 2.5 Flash
- **Temperature**: 0.1 (deterministic answers)
- **Max Tokens**: Adaptive based on context
- **Rate Limit**: 15 requests/minute (free tier)

---

## ğŸ”§ Configuration

### Key Settings (`src/config.py`)

```python
# Chunking
CHUNK_SIZE = 800              # Chars per chunk
CHUNK_OVERLAP = 200           # Overlap between chunks

# Retrieval
TOP_K_RETRIEVAL = 8           # Number of chunks to retrieve
SIMILARITY_THRESHOLD = 0.65   # Minimum similarity score

# Embeddings
EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"
EMBEDDING_BATCH_SIZE = 64     # Faster processing

# LLM
GEMINI_MODEL = "gemini-2.5-flash"
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Database
DB_HOST = "localhost"
DB_PORT = 5432
DB_NAME = "aviation_chatbot"
```

### Environment Variables

Create `.env` file:
```bash
GEMINI_API_KEY=your_api_key_here
DB_PASSWORD=aviation123
```

---

## ğŸŒ Deployment

### Docker Deployment (Recommended)

```dockerfile
# Dockerfile (to be created)
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8501

CMD ["streamlit", "run", "app.py"]
```

```bash
# Build and run
docker build -t aviation-chatbot .
docker run -p 8501:8501 aviation-chatbot
```

### Cloud Deployment Options

1. **Streamlit Cloud** (Easiest)
   - Connect GitHub repo
   - Add secrets in dashboard
   - Deploy with one click

2. **Heroku**
   ```bash
   heroku create aviation-chatbot
   heroku addons:create heroku-postgresql
   git push heroku main
   ```

3. **AWS/GCP/Azure**
   - Deploy with container service
   - Use managed PostgreSQL
   - Set environment variables

---

## ğŸ‘¨â€ğŸ’» Development

### Running Tests

```bash
# Test database connection
python -c "from src.db_utils import get_total_chunks; print(get_total_chunks())"

# Test RAG engine
python -c "from src.rag_engine import get_rag_engine; engine = get_rag_engine(); print('OK')"

# Test Gemini API
python -c "import google.generativeai as genai; genai.configure(api_key='YOUR_KEY'); print('OK')"
```

### Adding New Features

1. **Fork** the repository
2. **Create** feature branch: `git checkout -b feature/new-feature`
3. **Commit** changes: `git commit -m 'Add new feature'`
4. **Push** to branch: `git push origin feature/new-feature`
5. **Open** Pull Request

---

## ğŸ› Troubleshooting

### Common Issues

**1. Docker Container Not Running**
```bash
docker start aviation-postgres
docker ps  # Verify it's running
```

**2. API Key Error**
```bash
# Check if key is set
echo $GEMINI_API_KEY

# Or update config.py directly
GEMINI_API_KEY = "your-key-here"
```

**3. Import Errors**
```bash
pip install --upgrade sentence-transformers==2.7.0
pip install --upgrade huggingface_hub==0.23.0
```

**4. Database Connection Failed**
```bash
# Check PostgreSQL is running
docker logs aviation-postgres

# Verify credentials in config.py
DB_PASSWORD = "aviation123"
```

**5. Slow PDF Processing**
- Reduce batch size: `EMBEDDING_BATCH_SIZE = 32`
- Process smaller PDFs first
- Use faster embedding model (at cost of quality)

---

## ğŸš€ Future Enhancements

### Planned Features

- [ ] **Multi-language Support**: Translate documents and queries
- [ ] **Advanced Filters**: Search by date, author, document type
- [ ] **Export Conversations**: Download chat history as PDF
- [ ] **Voice Input**: Speech-to-text for hands-free queries
- [ ] **Collaborative Features**: Share queries and answers with team
- [ ] **Analytics Dashboard**: Track usage patterns and popular queries
- [ ] **Hybrid Search**: Combine vector and keyword search
- [ ] **Fine-tuned Model**: Custom embeddings for aviation terminology
- [ ] **API Endpoint**: RESTful API for integration with other tools
- [ ] **Mobile App**: Native iOS/Android applications

### Performance Optimizations

- [ ] **Caching**: Redis cache for frequent queries
- [ ] **Batch Processing**: Queue system for multiple PDF uploads
- [ ] **CDN**: Serve static assets from CDN
- [ ] **Load Balancing**: Horizontal scaling for high traffic

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

### Guidelines

1. Follow PEP 8 style guide
2. Add tests for new features
3. Update documentation
4. Keep commits atomic and well-described

---

## ğŸ‘ Acknowledgments

- **Google Gemini** for powerful LLM capabilities
- **Sentence Transformers** for efficient embeddings
- **PostgreSQL + pgvector** for vector database functionality
- **Streamlit** for rapid UI development
- **LangChain** for text processing utilities

---

## ğŸ“ Contact

**Project Maintainer**: Nithin Reddy
- GitHub: [@nithin8688](https://github.com/nithin8688)
- Email: nithin.dev8688@gmail.com

**Project Link**: https://github.com/nithin/aviation-chatbot

---

## ğŸ“Š Project Stats

- **Total Lines of Code**: ~2,500
- **Documents Indexed**: Unlimited (scalable)
- **Average Query Time**: 2-4 seconds
- **Supported PDF Size**: Up to 200MB per file
- **Database Size**: ~1.5MB per 1000 chunks

---

**Built with â¤ï¸ for the Aviation Community**

*Last Updated: January 2026*

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
